{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "212ce414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98177b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calidad_datos(x):\n",
    "    \n",
    "    # Modificar tipos\n",
    "    temp = x.astype({'month': 'O', 'wday': 'O'})             \n",
    "    \n",
    "    # Imputar nulos\n",
    "    temp.loc[x['event_name_1'].isna(),'event_name_1'] = 'Sin_evento'\n",
    "    \n",
    "    def imputar_moda(registros):\n",
    "        # Calcula la moda del precio en ese producto\n",
    "        moda = registros.sell_price.mode()[0]\n",
    "        # Imputa los nulos\n",
    "        registros.loc[registros.sell_price.isna(),'sell_price'] = moda\n",
    "        # Devuelve todos los registros del producto\n",
    "        return(registros)\n",
    "\n",
    "    temp = temp.groupby('item_id').apply(imputar_moda)\n",
    "      \n",
    "    return(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a57bd015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_variables(x):\n",
    "    \n",
    "    # DEMANDA INTERMITENTE\n",
    "    \n",
    "    def rotura_stock(ventas, n = 5):\n",
    "        cero_ventas = pd.Series(np.where(ventas == 0,1,0))\n",
    "        num_ceros = cero_ventas.rolling(n).sum()\n",
    "        rotura_stock = np.where(num_ceros == n,1,0)\n",
    "        return(rotura_stock)\n",
    "    \n",
    "    x = x.sort_values(by = ['store_id','item_id','date'])\n",
    "    x['rotura_stock_3'] = x.groupby(['store_id','item_id']).ventas.transform(lambda x: rotura_stock(x, 3)).values\n",
    "    x['rotura_stock_7'] = x.groupby(['store_id','item_id']).ventas.transform(lambda x: rotura_stock(x,7)).values\n",
    "    x['rotura_stock_15'] = x.groupby(['store_id','item_id']).ventas.transform(lambda x: rotura_stock(x,15)).values\n",
    "    \n",
    "    \n",
    "    # LAGS\n",
    "    \n",
    "    def crear_lags(x, variable, num_lags = 7):\n",
    "        lags = pd.DataFrame()\n",
    "        for cada in range(1,num_lags+1):\n",
    "            lags[variable + '_lag_'+ str(cada)] = x[variable].shift(cada)\n",
    "        return(lags)\n",
    "    \n",
    "    lags_sell_price_x = x.groupby(['store_id','item_id'])\\\n",
    "                    .apply(lambda x: crear_lags(x = x, variable = 'sell_price', num_lags= 7))\n",
    "    \n",
    "    lags_rotura_stock_3_x = x.groupby(['store_id','item_id'])\\\n",
    "                    .apply(lambda x: crear_lags(x = x, variable = 'rotura_stock_3', num_lags= 1))\n",
    "    \n",
    "    lags_rotura_stock_7_x = x.groupby(['store_id','item_id'])\\\n",
    "                    .apply(lambda x: crear_lags(x = x, variable = 'rotura_stock_7', num_lags= 1))\n",
    "    \n",
    "    lags_rotura_stock_15_x = x.groupby(['store_id','item_id'])\\\n",
    "                    .apply(lambda x: crear_lags(x = x, variable = 'rotura_stock_15', num_lags= 1))\n",
    "    \n",
    "    lags_ventas_x = x.groupby(['store_id','item_id'])\\\n",
    "                    .apply(lambda x: crear_lags(x = x, variable = 'ventas', num_lags= 15))\n",
    "    \n",
    "    \n",
    "    # VENTANAS MÓVILES\n",
    "    \n",
    "    def min_movil(x, variable, num_periodos = 7):\n",
    "        minm = pd.DataFrame()\n",
    "        for cada in range(2,num_periodos+1):\n",
    "            minm[variable + '_minm_' + str(cada)] = x[variable].shift(1).rolling(cada).min()\n",
    "        return(minm)\n",
    "    \n",
    "    def media_movil(x, variable, num_periodos = 7):\n",
    "        mm = pd.DataFrame()\n",
    "        for cada in range(2,num_periodos+1):\n",
    "            mm[variable + '_mm_' + str(cada)] = x[variable].shift(1).rolling(cada).mean()\n",
    "        return(mm)\n",
    "    \n",
    "    def max_movil(x, variable, num_periodos = 7):\n",
    "        maxm = pd.DataFrame()\n",
    "        for cada in range(2,num_periodos+1):\n",
    "            maxm[variable + '_maxm_' + str(cada)] = x[variable].shift(1).rolling(cada).max()\n",
    "        return(maxm)\n",
    "    \n",
    "    min_movil_x = x.groupby(['store_id','item_id'])\\\n",
    "                    .apply(lambda x: min_movil(x = x, variable = 'ventas', num_periodos= 15))\n",
    "    \n",
    "    media_movil_x = x.groupby(['store_id','item_id'])\\\n",
    "                    .apply(lambda x: media_movil(x = x, variable = 'ventas', num_periodos= 15))\n",
    "    \n",
    "    max_movil_x = x.groupby(['store_id','item_id'])\\\n",
    "                    .apply(lambda x: max_movil(x = x, variable = 'ventas', num_periodos= 15))\n",
    "    \n",
    "    \n",
    "    # UNIR DATAFRAMES GENERADOS\n",
    "    \n",
    "    x_unido = pd.concat([x,\n",
    "                      lags_sell_price_x,\n",
    "                      lags_rotura_stock_3_x,\n",
    "                      lags_rotura_stock_7_x,\n",
    "                      lags_rotura_stock_15_x,\n",
    "                      lags_ventas_x,\n",
    "                      min_movil_x,\n",
    "                      media_movil_x,\n",
    "                      max_movil_x], axis = 1)\n",
    "\n",
    "    x_unido.dropna(inplace=True)\n",
    "    \n",
    "    x_unido.drop(columns = ['sell_price','rotura_stock_3','rotura_stock_7','rotura_stock_15'],\n",
    "                  inplace=True)\n",
    "    \n",
    "    # Crear una sola variable para el producto\n",
    "    x_unido.insert(loc=0,column='producto',value=x_unido.store_id + '_'+ x_unido.item_id)\n",
    "    x_unido = x_unido.drop(columns = ['store_id','item_id'])\n",
    "    \n",
    "    return(x_unido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee711664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformar_variables(x,y=None,modo = 'entrenamiento'):\n",
    "    \n",
    "    '''\n",
    "    Función tanto para entrenamiento como para ejecución:\n",
    "    * Incluyendo el parámetro modo, que por defecto es entrenamiento.\n",
    "    * El parámetro 'y' es opcional, ya que en ejecución no se usa.\n",
    "\n",
    "    Cuando se usa en modo entrenamiento aplica el método fit_transform y guarda los objetos.\n",
    "\n",
    "    Cuando se usa en modo ejecución carga los objetos y aplica solo el método transform.\n",
    "    '''    \n",
    "    \n",
    "    x.reset_index(inplace = True)\n",
    "\n",
    "    # GESTION DE LOS ENCODERS\n",
    "    nombre_ohe = 'ohe_retail.pickle'\n",
    "    nombre_te = 'te_retail.pickle'\n",
    "    ruta_ohe = ruta_proyecto + '/04_Modelos/' + nombre_ohe\n",
    "    ruta_te = ruta_proyecto + '/04_Modelos/' + nombre_te\n",
    "    \n",
    "    # ONE HOT ENCODING\n",
    "    var_ohe = ['event_name_1']\n",
    "    if modo == 'entrenamiento':\n",
    "        # Si está en entrenamiento aplica fit_transform y guarda el encoder\n",
    "        ohe = OneHotEncoder(sparse = False, handle_unknown='ignore')\n",
    "        ohe_x = ohe.fit_transform(x[var_ohe])\n",
    "        ohe_x = pd.DataFrame(ohe_x, columns = ohe.get_feature_names_out())\n",
    "        with open(ruta_ohe, mode='wb') as file:\n",
    "           pickle.dump(ohe, file)\n",
    "    else:\n",
    "        # Si está en ejecución recupera el guardado y solo aplica transform\n",
    "        with open(ruta_ohe, mode='rb') as file:\n",
    "            ohe = pickle.load(file)\n",
    "        ohe_x = ohe.transform(x[var_ohe])\n",
    "        ohe_x = pd.DataFrame(ohe_x, columns = ohe.get_feature_names_out())\n",
    "\n",
    "    # TARGET ENCODING    \n",
    "    var_te = ['month','wday','weekday']\n",
    "    if modo == 'entrenamiento':\n",
    "        # ASEGURAR QUE Y TIENE LOS MISMOS REGISTROS QUE X\n",
    "        y.reset_index(inplace = True, drop = True)\n",
    "        y = y.loc[y.index.isin(x.index)]\n",
    "        # Si está en entrenamiento aplica fit_transform y guarda el encoder\n",
    "        te = TargetEncoder(min_samples_leaf=100, return_df = False)\n",
    "        te_x = te.fit_transform(x[var_te], y = y)\n",
    "        nombres_te = [variable + '_te' for variable in var_te]\n",
    "        te_x = pd.DataFrame(te_x, columns = nombres_te)\n",
    "        with open(ruta_te, mode='wb') as file:\n",
    "           pickle.dump(te, file)\n",
    "    else:\n",
    "        # Si está en ejecución recupera el guardado y solo aplica transform\n",
    "        with open(ruta_te, mode='rb') as file:\n",
    "            te = pickle.load(file)\n",
    "        te_x = te.transform(x[var_te])\n",
    "        nombres_te = [variable + '_te' for variable in var_te]\n",
    "        te_x = pd.DataFrame(te_x, columns = nombres_te)\n",
    "    \n",
    "      \n",
    "    # INTEGRAR, LIMPIAR Y DEVOLVER EL DATAFRAME\n",
    "    # Eliminar las originales ya transformadas\n",
    "    x = x.drop(columns=['event_name_1','month','wday','weekday'])\n",
    "    # Incorporar los otros dataframes\n",
    "    x = pd.concat([x,ohe_x,te_x], axis=1).set_index('date')\n",
    "\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88ebaa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preseleccionar_variables(x,y):\n",
    "    \n",
    "    '''\n",
    "    Solo para entrenamiento.\n",
    "    '''\n",
    "    # ELIMINAR LA COLUMNA PRODUCTO Y EL INDEX\n",
    "    x.reset_index(drop = True,inplace = True)\n",
    "    x.drop(columns='producto',inplace = True)\n",
    "    \n",
    "    # ASEGURAR QUE Y TIENE LOS MISMOS REGISTROS QUE X\n",
    "    y = y.loc[y.index.isin(x.index)]\n",
    "    \n",
    "\n",
    "    mutual_selector = mutual_info_regression(x,y)\n",
    "    posicion_variable_limite = 70\n",
    "    ranking_mi = pd.DataFrame(mutual_selector, index = x.columns).reset_index()\n",
    "    ranking_mi.columns = ['variable','importancia_mi']\n",
    "    ranking_mi = ranking_mi.sort_values(by = 'importancia_mi', ascending = False)\n",
    "    ranking_mi['ranking_mi'] = np.arange(0,ranking_mi.shape[0])\n",
    "    entran_mi = ranking_mi.iloc[0:posicion_variable_limite].variable\n",
    "    x_mi = x[entran_mi].copy()\n",
    "\n",
    "    return(x_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81e214da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelizar(x_producto, y):\n",
    "    \n",
    "    '''\n",
    "    Función que hace la modelización individual.\n",
    "\n",
    "    Recibe los datos de las x y la y de un producto.\n",
    "\n",
    "    Encuentra los parámetros óptimos para ese producto.\n",
    "\n",
    "    Devuelve el mejor modelo.\n",
    "    '''\n",
    "      \n",
    "    # Excluye el producto como variable de modelización\n",
    "    var_modelizar = x_producto.columns.to_list()[2:]\n",
    "    \n",
    "    # Define la validación cruzada\n",
    "    time_cv = TimeSeriesSplit(5, test_size = 8)\n",
    "    \n",
    "    # Define la parrilla de algoritmos\n",
    "    pipe = Pipeline([('algoritmo',HistGradientBoostingRegressor())])\n",
    "    \n",
    "    grid = [ \n",
    "         {'algoritmo': [HistGradientBoostingRegressor()]\n",
    "#          'algoritmo__learning_rate': [0.01,0.025,0.05,0.1],\n",
    "#          'algoritmo__max_iter': [50,100,200],\n",
    "#          'algoritmo__max_depth': [5,10,20,50],\n",
    "#          'algoritmo__scoring': ['neg_mean_absolute_error'],\n",
    "#          'algoritmo__l2_regularization': [0,0.25,0.5,0.75,1]\n",
    "         }\n",
    "                       \n",
    "    ]\n",
    "           \n",
    "    # Crea los modelos\n",
    "    random_search = RandomizedSearchCV(estimator = pipe,\n",
    "                                   param_distributions = grid, \n",
    "                                   n_iter = 1, \n",
    "                                   cv = time_cv, \n",
    "                                   scoring = 'neg_mean_absolute_error', \n",
    "                                   verbose = 0,\n",
    "                                   n_jobs = -1)\n",
    "    \n",
    "    modelo = random_search.fit(x_producto[var_modelizar],y)\n",
    "    \n",
    "    # Reentrena el mejor sobre todos los datos\n",
    "    modelo_final = modelo.best_estimator_.fit(x_producto[var_modelizar],y)\n",
    "    \n",
    "    # Devuelve como salida el modelo final\n",
    "    return(modelo_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33a52d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lanzar_entrenamiento(df):\n",
    "    \n",
    "    '''\n",
    "    Esta función va recorriendo todos los productos y llamando a modelizar() para crear una lista total con todos los modelos de todos los productos.\n",
    "\n",
    "    Recibe el dataframe de las x ya limpio y segmentado por producto, y también la target.\n",
    "\n",
    "    No devuelve nada, si no que guarda en disco el objeto ya entrenado con todos los modelos.\n",
    "    '''\n",
    "    \n",
    "    lista_productos = list(df.producto.unique())\n",
    "    \n",
    "    lista_modelos =[] \n",
    "    \n",
    "    for cada in lista_productos:\n",
    "        \n",
    "        # Renombra por claridad\n",
    "        producto = cada\n",
    "        target = 'ventas'\n",
    "\n",
    "        x = df.loc[df.producto == producto].copy().drop(columns=target).copy()\n",
    "        y = df.loc[df.producto == producto,'ventas'].copy()\n",
    "\n",
    "        x = transformar_variables(x,y)\n",
    "        x = preseleccionar_variables(x,y)\n",
    "        \n",
    "        # Llama a la funcion de modelizar\n",
    "        modelo = modelizar(x,y)\n",
    "        \n",
    "        # Añade el modelo final a la lista\n",
    "        lista_modelos.append((producto,modelo))\n",
    "        \n",
    "    # Guarda la lista de modelos entrenados\n",
    "    nombre_modelos = 'lista_modelos_retail.pickle'\n",
    "    ruta_modelos = ruta_proyecto + '/04_Modelos/' + nombre_modelos\n",
    "    with open(ruta_modelos, mode='wb') as file:\n",
    "       pickle.dump(lista_modelos, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f63eaf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lanzar_ejecucion(df):\n",
    "    \n",
    "    '''\n",
    "    Esta función hace el forecast para cada producto, pero solo de un día.\n",
    "\n",
    "    Recibe el nuevo dataset a predecir, con la estructura del fichero DatosParaProduccion.csv de la carpeta Validación.\n",
    "\n",
    "    Va recorriendo cada producto, cargando su modelo correspondiente, seleccionando sus datos, y haciendo las predicciones.\n",
    "\n",
    "    Devuelve la predicción para todos los productos pero SOLO PARA EL DÍA QUE TOCA.\n",
    "    '''\n",
    "    \n",
    "    # CARGA LOS MODELOS\n",
    "    nombre_modelos = 'lista_modelos_retail.pickle'\n",
    "    ruta_modelos = ruta_proyecto + '/04_Modelos/' + nombre_modelos\n",
    "    with open(ruta_modelos, mode='rb') as file:\n",
    "       lista_modelos = pickle.load(file)\n",
    "    \n",
    "    predicciones_df = pd.DataFrame(columns=['date','producto','ventas','prediccion'])\n",
    "    \n",
    "    for cada in range(0,len(lista_modelos)):\n",
    "\n",
    "        producto = lista_modelos[cada][0]\n",
    "        modelo = lista_modelos[cada][1]\n",
    "        variables = modelo[0].feature_names_in_\n",
    "        target = 'ventas'\n",
    "        \n",
    "        x = df.loc[df.producto == producto].copy().drop(columns=target).copy()\n",
    "        y = df.loc[df.producto == producto,'ventas'].copy()\n",
    "        \n",
    "        date = df.reset_index().copy()\n",
    "        date = date.loc[date.producto == producto,'date'].values\n",
    "\n",
    "        #Transformacion de variables\n",
    "        x = transformar_variables(x, modo = 'ejecucion')\n",
    "        \n",
    "        #Seleccion de variables\n",
    "        x = x[variables]\n",
    "        \n",
    "        #Cálculo de predicciones\n",
    "        predicciones = pd.DataFrame(data={'date': date,\n",
    "                                          'producto': producto,\n",
    "                                          'ventas': y,\n",
    "                                          'prediccion': modelo.predict(x)})\n",
    "\n",
    "        predicciones['prediccion'] = predicciones.prediccion.astype('int')\n",
    "\n",
    "        predicciones_df = pd.concat([predicciones_df,predicciones])\n",
    "    \n",
    "    predicciones_df = predicciones_df.loc[predicciones_df.index == predicciones_df.index.min()]\n",
    "    return(predicciones_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c4a5d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_recursivo(x):\n",
    "    \n",
    "    '''\n",
    "    Esta función es la que aplica el forecast recursivo para predecir 8 días.\n",
    "    \n",
    "    Recibe el nuevo dataset a predecir con la estructura del fichero DatosParaProduccion.csv de la carpeta Validación. \n",
    "    \n",
    "    Para aplicar la recursividad:\n",
    "    * Va a predecir el primer día para el cual tenga toda la información (es decir 15 días desde el día más antiguo).\n",
    "    * Al finalizar graba la predicción de ventas en el registro a predecir y elimina los registros del día más antiguo del dataframe.\n",
    "    * Por tanto en la siguiente iteración va a predecir el siguiente día.\n",
    "\n",
    "    Por ejemplo:\n",
    "\n",
    "    Si el día más antiguo del dataset es el 09/12/2015 entonces el primer día que puede predecir\n",
    "    \n",
    "    (y del cual ya no tenemos dato) es el 24/12/2015.\n",
    "\n",
    "    Cuando predice el dato del 24 para cada producto lo sobrescribe como sus ventas\n",
    "    \n",
    "    y elimina todos los registros del día 09.\n",
    "\n",
    "    Entonces el día más antiguo pasa a ser el día 10 y por tanto el día a predecir es el 25.\n",
    "\n",
    "    Y así hasta que finaliza 8 ciclos para predecir la semana que queremos.\n",
    "    '''\n",
    "    \n",
    "    for cada in range(0,8):\n",
    "        paso1_df = calidad_datos(x)\n",
    "        paso2_df = crear_variables(paso1_df)\n",
    "        \n",
    "        # Calcula la predicción\n",
    "        f = lanzar_ejecucion(paso2_df)\n",
    "        f['store_id'] = f.producto.str[:4]\n",
    "        f['item_id'] = f.producto.str[5:]\n",
    "\n",
    "        # Actualiza el dato de ventas con la predicción\n",
    "        x.loc[(x.index.isin(f.date)) & (x.store_id.isin(f.store_id)) & (x.item_id.isin(f.item_id)),'ventas'] = f.prediccion\n",
    "                                                              \n",
    "        # Elimina el día más antiguo de x\n",
    "        x = x.loc[x.index != x.index.min()]\n",
    "        \n",
    "    return(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "176px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
